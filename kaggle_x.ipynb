{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Used Car Price Prediction\n",
        "\n",
        "The goal of this notebook is to predict the price of a used vehicle given 12 distinct features such as brand, model, mileage etc.\n",
        "\n",
        "Using the dataset, i build visualizations to understand the underlying factors affecting the price of a used car. Finally we shall build a model to predict the final price of a used car."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports\n",
        "\n",
        "Here i install and import all the libraries neccessary to run this notebook"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install catboost\n",
        "%pip install optuna\n",
        "%pip install optuna_distributed\n",
        "%pip install openfe\n",
        "%pip install seaborn\n",
        "%pip install -q -U autogluon.tabular\n",
        "%pip install -Uqq fastbook\n",
        "import fastbook\n",
        "%fastbook.setup_book()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: catboost in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (1.2.5)\nRequirement already satisfied: graphviz in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from catboost) (0.20.3)\nRequirement already satisfied: matplotlib in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from catboost) (3.7.1)\nRequirement already satisfied: numpy>=1.16.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from catboost) (1.23.5)\nRequirement already satisfied: pandas>=0.24 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from catboost) (2.0.2)\nRequirement already satisfied: scipy in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from catboost) (1.9.1)\nRequirement already satisfied: plotly in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from catboost) (5.15.0)\nRequirement already satisfied: six in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from catboost) (1.16.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from pandas>=0.24->catboost) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from pandas>=0.24->catboost) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from pandas>=0.24->catboost) (2023.3)\nRequirement already satisfied: contourpy>=1.0.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib->catboost) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib->catboost) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib->catboost) (4.40.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib->catboost) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib->catboost) (23.0)\nRequirement already satisfied: pillow>=6.2.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib->catboost) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib->catboost) (3.1.0)\nRequirement already satisfied: importlib-resources>=3.2.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib->catboost) (5.12.0)\nRequirement already satisfied: tenacity>=6.2.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from plotly->catboost) (8.2.2)\nRequirement already satisfied: zipp>=3.1.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib->catboost) (3.15.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: optuna in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (3.6.1)\nRequirement already satisfied: alembic>=1.5.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from optuna) (1.13.1)\nRequirement already satisfied: colorlog in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from optuna) (6.8.2)\nRequirement already satisfied: numpy in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from optuna) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from optuna) (23.0)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from optuna) (2.0.30)\nRequirement already satisfied: tqdm in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from optuna) (4.65.0)\nRequirement already satisfied: PyYAML in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from optuna) (6.0)\nRequirement already satisfied: Mako in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (1.3.5)\nRequirement already satisfied: typing-extensions>=4 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (4.6.3)\nRequirement already satisfied: importlib-metadata in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (6.7.0)\nRequirement already satisfied: importlib-resources in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (5.12.0)\nRequirement already satisfied: greenlet!=0.4.17 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\nRequirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.15.0)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: optuna_distributed in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (0.6.2)\nRequirement already satisfied: optuna>=3.1.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from optuna_distributed) (3.6.1)\nRequirement already satisfied: dask[distributed] in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from optuna_distributed) (2023.5.0)\nRequirement already satisfied: rich in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from optuna_distributed) (13.7.1)\nRequirement already satisfied: alembic>=1.5.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from optuna>=3.1.0->optuna_distributed) (1.13.1)\nRequirement already satisfied: colorlog in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from optuna>=3.1.0->optuna_distributed) (6.8.2)\nRequirement already satisfied: numpy in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from optuna>=3.1.0->optuna_distributed) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from optuna>=3.1.0->optuna_distributed) (23.0)\nRequirement already satisfied: sqlalchemy>=1.3.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from optuna>=3.1.0->optuna_distributed) (2.0.30)\nRequirement already satisfied: tqdm in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from optuna>=3.1.0->optuna_distributed) (4.65.0)\nRequirement already satisfied: PyYAML in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from optuna>=3.1.0->optuna_distributed) (6.0)\nRequirement already satisfied: click>=8.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from dask[distributed]->optuna_distributed) (8.1.3)\nRequirement already satisfied: cloudpickle>=1.5.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from dask[distributed]->optuna_distributed) (2.2.1)\nRequirement already satisfied: fsspec>=2021.09.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from dask[distributed]->optuna_distributed) (2024.3.1)\nRequirement already satisfied: partd>=1.2.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from dask[distributed]->optuna_distributed) (1.4.1)\nRequirement already satisfied: toolz>=0.10.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from dask[distributed]->optuna_distributed) (0.12.1)\nRequirement already satisfied: importlib-metadata>=4.13.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from dask[distributed]->optuna_distributed) (6.7.0)\nRequirement already satisfied: distributed==2023.5.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from dask[distributed]->optuna_distributed) (2023.5.0)\nRequirement already satisfied: jinja2>=2.10.3 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from distributed==2023.5.0->dask[distributed]->optuna_distributed) (3.1.2)\nRequirement already satisfied: locket>=1.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from distributed==2023.5.0->dask[distributed]->optuna_distributed) (1.0.0)\nRequirement already satisfied: msgpack>=1.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from distributed==2023.5.0->dask[distributed]->optuna_distributed) (1.0.8)\nRequirement already satisfied: psutil>=5.7.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from distributed==2023.5.0->dask[distributed]->optuna_distributed) (5.9.0)\nRequirement already satisfied: sortedcontainers>=2.0.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from distributed==2023.5.0->dask[distributed]->optuna_distributed) (2.4.0)\nRequirement already satisfied: tblib>=1.6.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from distributed==2023.5.0->dask[distributed]->optuna_distributed) (3.0.0)\nRequirement already satisfied: tornado>=6.0.3 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from distributed==2023.5.0->dask[distributed]->optuna_distributed) (6.3.2)\nRequirement already satisfied: urllib3>=1.24.3 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from distributed==2023.5.0->dask[distributed]->optuna_distributed) (1.26.16)\nRequirement already satisfied: zict>=2.2.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from distributed==2023.5.0->dask[distributed]->optuna_distributed) (3.0.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from rich->optuna_distributed) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from rich->optuna_distributed) (2.15.1)\nRequirement already satisfied: typing-extensions<5.0,>=4.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from rich->optuna_distributed) (4.6.3)\nRequirement already satisfied: Mako in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from alembic>=1.5.0->optuna>=3.1.0->optuna_distributed) (1.3.5)\nRequirement already satisfied: importlib-resources in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from alembic>=1.5.0->optuna>=3.1.0->optuna_distributed) (5.12.0)\nRequirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from importlib-metadata>=4.13.0->dask[distributed]->optuna_distributed) (3.15.0)\nRequirement already satisfied: mdurl~=0.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich->optuna_distributed) (0.1.2)\nRequirement already satisfied: greenlet!=0.4.17 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from sqlalchemy>=1.3.0->optuna>=3.1.0->optuna_distributed) (3.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from jinja2>=2.10.3->distributed==2023.5.0->dask[distributed]->optuna_distributed) (2.1.3)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: openfe in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (0.0.12)\nRequirement already satisfied: numpy>=1.19.3 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from openfe) (1.23.5)\nRequirement already satisfied: pandas>=1.1.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from openfe) (2.0.2)\nRequirement already satisfied: scikit-learn>=0.24.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from openfe) (1.3.2)\nRequirement already satisfied: lightgbm>=3.3.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from openfe) (3.3.5)\nRequirement already satisfied: scipy>=1.5.4 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from openfe) (1.9.1)\nRequirement already satisfied: tqdm in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from openfe) (4.65.0)\nRequirement already satisfied: pyarrow in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from openfe) (16.1.0)\nRequirement already satisfied: wheel in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from lightgbm>=3.3.2->openfe) (0.43.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from pandas>=1.1.5->openfe) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from pandas>=1.1.5->openfe) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from pandas>=1.1.5->openfe) (2023.3)\nRequirement already satisfied: joblib>=1.1.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from scikit-learn>=0.24.2->openfe) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from scikit-learn>=0.24.2->openfe) (3.1.0)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->openfe) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: seaborn in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (0.13.2)\nRequirement already satisfied: numpy!=1.24.0,>=1.20 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from seaborn) (1.23.5)\nRequirement already satisfied: pandas>=1.2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from seaborn) (2.0.2)\nRequirement already satisfied: matplotlib!=3.6.1,>=3.4 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from seaborn) (3.7.1)\nRequirement already satisfied: contourpy>=1.0.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.40.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.0)\nRequirement already satisfied: pillow>=6.2.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.0)\nRequirement already satisfied: python-dateutil>=2.7 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\nRequirement already satisfied: importlib-resources>=3.2.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (5.12.0)\nRequirement already satisfied: pytz>=2020.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from pandas>=1.2->seaborn) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from pandas>=1.2->seaborn) (2023.3)\nRequirement already satisfied: zipp>=3.1.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn) (3.15.0)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\nNote: you may need to restart the kernel to use updated packages.\nNote: you may need to restart the kernel to use updated packages.\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "UsageError: Line magic function `%fastbook.setup_book()` not found.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": true
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719386675089
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastbook import *\n",
        "\n",
        "from fastai.tabular.all import *\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "from tqdm import tqdm\n",
        "from ipywidgets import interact\n",
        "\n",
        "from fastai.imports import *\n",
        "np.set_printoptions(linewidth=130)\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score,accuracy_score,mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#transformers and pipeline\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn import set_config\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import plot_importance\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from catboost import CatBoostClassifier,CatBoostRegressor,Pool, metrics, cv\n",
        "\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.visualization import plot_contour\n",
        "from optuna.visualization import plot_edf\n",
        "from optuna.visualization import plot_intermediate_values\n",
        "from optuna.visualization import plot_optimization_history\n",
        "from optuna.visualization import plot_parallel_coordinate\n",
        "from optuna.visualization import plot_param_importances\n",
        "from optuna.visualization import plot_slice\n",
        "from optuna.samplers import TPESampler\n",
        "import warnings\n",
        "\n",
        "matplotlib.rc('image', cmap='Greys')\n",
        "\n",
        "#from fastkaggle import setup_comp\n",
        "\n",
        "from openfe import OpenFE, transform\n",
        "\n",
        "from autogluon.tabular import TabularDataset, TabularPredictor"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1719386751614
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try: import fastkaggle\n",
        "except ModuleNotFoundError:\n",
        "    !pip install -Uq fastkaggle\n",
        "\n",
        "from fastkaggle import *"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719386752578
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "LICENSE      kaggle_x.ipynb\t    used-car-price-prediction-dataset.zip\r\nREADME.md    kaggle_x.ipynb.amltmp\r\nkaggle.json  kagglex-cohort4.zip\r\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "\n",
        "#!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "mkdir: cannot create directory ‘/home/azureuser/.kaggle’: File exists\r\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719387355394
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Datasets"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c kagglex-cohort4"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/azureuser/.kaggle/kaggle.json'\nDownloading kagglex-cohort4.zip to /mnt/batch/tasks/shared/LS_root/mounts/clusters/kenpachislime1/code/Users/kenpachislime/kaggle_x\n 46%|█████████████████▌                    | 1.00M/2.17M [00:00<00:00, 8.93MB/s]\n100%|██████████████████████████████████████| 2.17M/2.17M [00:00<00:00, 8.38MB/s]\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Original dataset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d taeefnajib/used-car-price-prediction-dataset"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/azureuser/.kaggle/kaggle.json'\nDataset URL: https://www.kaggle.com/datasets/taeefnajib/used-car-price-prediction-dataset\nLicense(s): Attribution 4.0 International (CC BY 4.0)\nDownloading used-car-price-prediction-dataset.zip to /mnt/batch/tasks/shared/LS_root/mounts/clusters/kenpachislime1/code/Users/kenpachislime/kaggle_x\n  0%|                                                | 0.00/109k [00:00<?, ?B/s]\n100%|████████████████████████████████████████| 109k/109k [00:00<00:00, 1.30MB/s]\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls dataset/original"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir dataset\n",
        "!chmod +w dataset\n",
        "!mkdir dataset/original\n",
        "!chmod +w dataset/original"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717678548847
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip kagglex-cohort4.zip -d dataset\n",
        "!unzip used-car-price-prediction-dataset.zip -d dataset/original/"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Archive:  kagglex-cohort4.zip\n  inflating: dataset/sample_submission.csv  \n  inflating: dataset/test.csv        \n  inflating: dataset/train.csv       \nArchive:  used-car-price-prediction-dataset.zip\n  inflating: dataset/original/used_cars.csv  \n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717679357609
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls dataset/original"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "used_cars.csv\r\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = Path('dataset/')\n",
        "path"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "Path('dataset')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719387523775
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define DataFrames"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(path/'train.csv',index_col='id')\n",
        "test_df = pd.read_csv(path/'test.csv',index_col='id')\n",
        "sub_df = pd.read_csv(path/'sample_submission.csv')\n",
        "original_df = pd.read_csv(path/'original/used_cars.csv')"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719387527904
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head(2)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "   brand         model  model_year  milage fuel_type  \\\nid                                                     \n0   Ford  F-150 Lariat        2018   74349  Gasoline   \n1    BMW         335 i        2007   80000  Gasoline   \n\n                                                   engine  transmission  \\\nid                                                                        \n0           375.0HP 3.5L V6 Cylinder Engine Gasoline Fuel  10-Speed A/T   \n1   300.0HP 3.0L Straight 6 Cylinder Engine Gasoline Fuel   6-Speed M/T   \n\n   ext_col int_col       accident clean_title  price  \nid                                                    \n0     Blue    Gray  None reported         Yes  11000  \n1    Black   Black  None reported         Yes   8250  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>brand</th>\n      <th>model</th>\n      <th>model_year</th>\n      <th>milage</th>\n      <th>fuel_type</th>\n      <th>engine</th>\n      <th>transmission</th>\n      <th>ext_col</th>\n      <th>int_col</th>\n      <th>accident</th>\n      <th>clean_title</th>\n      <th>price</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Ford</td>\n      <td>F-150 Lariat</td>\n      <td>2018</td>\n      <td>74349</td>\n      <td>Gasoline</td>\n      <td>375.0HP 3.5L V6 Cylinder Engine Gasoline Fuel</td>\n      <td>10-Speed A/T</td>\n      <td>Blue</td>\n      <td>Gray</td>\n      <td>None reported</td>\n      <td>Yes</td>\n      <td>11000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BMW</td>\n      <td>335 i</td>\n      <td>2007</td>\n      <td>80000</td>\n      <td>Gasoline</td>\n      <td>300.0HP 3.0L Straight 6 Cylinder Engine Gasoline Fuel</td>\n      <td>6-Speed M/T</td>\n      <td>Black</td>\n      <td>Black</td>\n      <td>None reported</td>\n      <td>Yes</td>\n      <td>8250</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719387530325
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_df.head(2)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "     brand                            model  model_year      milage  \\\n0     Ford  Utility Police Interceptor Base        2013  51,000 mi.   \n1  Hyundai                     Palisade SEL        2021  34,742 mi.   \n\n       fuel_type                                                engine  \\\n0  E85 Flex Fuel  300.0HP 3.7L V6 Cylinder Engine Flex Fuel Capability   \n1       Gasoline                                  3.8L V6 24V GDI DOHC   \n\n        transmission          ext_col int_col  \\\n0        6-Speed A/T            Black   Black   \n1  8-Speed Automatic  Moonlight Cloud    Gray   \n\n                                 accident clean_title    price  \n0  At least 1 accident or damage reported         Yes  $10,300  \n1  At least 1 accident or damage reported         Yes  $38,005  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>brand</th>\n      <th>model</th>\n      <th>model_year</th>\n      <th>milage</th>\n      <th>fuel_type</th>\n      <th>engine</th>\n      <th>transmission</th>\n      <th>ext_col</th>\n      <th>int_col</th>\n      <th>accident</th>\n      <th>clean_title</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Ford</td>\n      <td>Utility Police Interceptor Base</td>\n      <td>2013</td>\n      <td>51,000 mi.</td>\n      <td>E85 Flex Fuel</td>\n      <td>300.0HP 3.7L V6 Cylinder Engine Flex Fuel Capability</td>\n      <td>6-Speed A/T</td>\n      <td>Black</td>\n      <td>Black</td>\n      <td>At least 1 accident or damage reported</td>\n      <td>Yes</td>\n      <td>$10,300</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Hyundai</td>\n      <td>Palisade SEL</td>\n      <td>2021</td>\n      <td>34,742 mi.</td>\n      <td>Gasoline</td>\n      <td>3.8L V6 24V GDI DOHC</td>\n      <td>8-Speed Automatic</td>\n      <td>Moonlight Cloud</td>\n      <td>Gray</td>\n      <td>At least 1 accident or damage reported</td>\n      <td>Yes</td>\n      <td>$38,005</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719387531713
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original df price has a $ as the train_df doesnt"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape,test_df.shape,original_df.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "((54273, 12), (36183, 11), (4009, 12))"
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719387532393
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.columns,test_df.columns"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "(Index(['brand', 'model', 'model_year', 'milage', 'fuel_type', 'engine',\n        'transmission', 'ext_col', 'int_col', 'accident', 'clean_title',\n        'price'],\n       dtype='object'),\n Index(['brand', 'model', 'model_year', 'milage', 'fuel_type', 'engine',\n        'transmission', 'ext_col', 'int_col', 'accident', 'clean_title'],\n       dtype='object'))"
          },
          "metadata": {}
        }
      ],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719387533145
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cont_names,cat_names = cont_cat_split(train_df, dep_var='price')\n",
        "splits = RandomSplitter(valid_pct=0.2)(range_of(train_df))\n",
        "to = TabularPandas(train_df, procs=[Categorify, FillMissing,Normalize],\n",
        "                   cat_names = cat_names,\n",
        "                   cont_names = cont_names,\n",
        "                   y_names='price',\n",
        "                   splits=splits)\n",
        "\n",
        "X_train, y_train = to.train.xs, to.train.ys.values.ravel()\n",
        "X_test, y_test = to.valid.xs, to.valid.ys.values.ravel()\n",
        "\n",
        "dls = to.dataloaders(bs=64)\n",
        "test_dl = dls.test_dl(test_df)"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719387542044
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optuna"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 100, 500),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0, log=True),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 300, 1200),\n",
        "        'subsample_for_bin': trial.suggest_int('subsample_for_bin', 20000, 300000),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 20, 500),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-9, 10.0, log=True),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-9, 10.0, log=True),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n",
        "        'subsample': trial.suggest_float('subsample', 0.25, 1.0),\n",
        "        'max_depth': trial.suggest_int('max_depth', 1, 15)\n",
        "    }\n",
        "    \n",
        "    model = LGBMClassifier(**params, objective='multiclass', random_state=0, device='cpu', verbosity=-1)\n",
        "    \n",
        "    # Cross-validation with 5 folds using KFold\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    cv_results = cross_val_score(model, X_train, y_train, cv=kf, scoring='accuracy')\n",
        "    \n",
        "    # We maximize accuracy, so we return the mean accuracy of the cross-validation\n",
        "    return np.mean(cv_results)\n",
        "\n",
        "study = optuna.create_study(sampler=TPESampler(n_startup_trials=30, multivariate=True, seed=0), direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "print('Best value:', study.best_value)\n",
        "print('Best trial:', study.best_trial.params)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from lightgbm import LGBMClassifier\n",
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 100, 500),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0, log=True),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 300, 1200),\n",
        "        'subsample_for_bin': trial.suggest_int('subsample_for_bin', 20000, 300000),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 20, 500),\n",
        "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-9, 10.0, log=True),\n",
        "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-9, 10.0, log=True),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n",
        "        'subsample': trial.suggest_float('subsample', 0.25, 1.0),\n",
        "        'max_depth': trial.suggest_int('max_depth', 1, 15)\n",
        "    }\n",
        "    \n",
        "    model = LGBMClassifier(**params, objective='regression', random_state=0, device='cpu', verbosity=-1)\n",
        "    \n",
        "    # Cross-validation with 5 folds using KFold\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    cv_results = cross_val_score(model, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')  # Use neg_mean_squared_error for RMSE\n",
        "    \n",
        "    # We minimize RMSE, so we return the negative mean squared error (to convert it to a maximization problem)\n",
        "    return -np.mean(cv_results)\n",
        "\n",
        "study = optuna.create_study(sampler=TPESampler(n_startup_trials=30, multivariate=True, seed=0), direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "print('Best value:', study.best_value)\n",
        "print('Best trial:', study.best_trial.params)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/optuna/samplers/_tpe/sampler.py:319: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n  warnings.warn(\n[I 2024-06-23 19:53:25,243] A new study created in memory with name: no-name-50970b2a-d4a6-4a41-99c8-8306af1a676d\n[I 2024-06-23 21:13:53,573] Trial 0 finished with value: 222051582.47651833 and parameters: {'num_leaves': 320, 'learning_rate': 0.269388301928541, 'n_estimators': 843, 'subsample_for_bin': 172567, 'min_child_samples': 223, 'reg_alpha': 0.0028770084050677926, 'reg_lambda': 2.3761404778025532e-05, 'colsample_bytree': 0.9350638004692479, 'subsample': 0.9727470703757719, 'max_depth': 6}. Best is trial 0 with value: 222051582.47651833.\n[I 2024-06-23 22:32:41,836] Trial 1 finished with value: 254752551.68751606 and parameters: {'num_leaves': 417, 'learning_rate': 0.11423254155608371, 'n_estimators': 811, 'subsample_for_bin': 279167, 'min_child_samples': 54, 'reg_alpha': 7.435205853060191e-09, 'reg_lambda': 1.5928833561691813e-09, 'colsample_bytree': 0.8995719073287628, 'subsample': 0.8336175632123879, 'max_depth': 14}. Best is trial 1 with value: 254752551.68751606.\n[I 2024-06-23 23:31:02,602] Trial 2 finished with value: 201398000.99417645 and parameters: {'num_leaves': 492, 'learning_rate': 0.39656750817710085, 'n_estimators': 715, 'subsample_for_bin': 238548, 'min_child_samples': 76, 'reg_alpha': 0.0025073225886269243, 'reg_lambda': 2.7135190452611042e-08, 'colsample_bytree': 0.9668013502297503, 'subsample': 0.6413862413125537, 'max_depth': 7}. Best is trial 1 with value: 254752551.68751606.\n[I 2024-06-24 00:31:27,671] Trial 3 finished with value: 236515931.28070813 and parameters: {'num_leaves': 206, 'learning_rate': 0.35356346291488117, 'n_estimators': 710, 'subsample_for_bin': 179162, 'min_child_samples': 29, 'reg_alpha': 0.0015009111045464082, 'reg_lambda': 0.0013211655088884039, 'colsample_bytree': 0.7701603981248542, 'subsample': 0.9578110588859681, 'max_depth': 11}. Best is trial 1 with value: 254752551.68751606.\n[I 2024-06-24 03:04:41,849] Trial 4 finished with value: 144324789.78566605 and parameters: {'num_leaves': 244, 'learning_rate': 0.07482796037620795, 'n_estimators': 928, 'subsample_for_bin': 36863, 'min_child_samples': 340, 'reg_alpha': 0.005086027407695681, 'reg_lambda': 1.270064013533415e-07, 'colsample_bytree': 0.477355778592912, 'subsample': 0.4865712631931379, 'max_depth': 6}. Best is trial 1 with value: 254752551.68751606.\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Best value:', study.best_value)\n",
        "print('Best trial:', study.best_trial.params)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "rf = RandomForestRegressor(100, min_samples_leaf=3)\n",
        "rf_model = rf.fit(X_train, y_train);\n",
        "\n",
        "rf_preds = tensor(rf_model.predict(test_dl.xs))\n",
        "\n",
        "rf_preds_x = tensor(rf_model.predict(X_test))\n",
        "\n",
        "mse = mean_squared_error(y_test, rf_preds_x)\n",
        "rmse = np.sqrt(mse)\n",
        "print(rmse)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "58749.51853846713\nCPU times: user 17.4 s, sys: 42.4 ms, total: 17.4 s\nWall time: 17.4 s\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(y_test, rf_preds_x)\n",
        "rmse = np.sqrt(mse)\n",
        "print(rmse)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "74318.74025617407\n"
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719157759264
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "cat_model = CatBoostRegressor(iterations=2000, depth=8, learning_rate=  0.08, random_strength=10)\n",
        "cat_model = cat_model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)\n",
        "\n",
        "#test set preds\n",
        "cat_preds = tensor(cat_model.predict(test_dl.xs))\n",
        "\n",
        "#validation set preds\n",
        "cat_preds_x = tensor(cat_model.predict(X_test))\n",
        "\n",
        "mse = mean_squared_error(y_test, cat_preds_x)\n",
        "rmse = np.sqrt(mse)\n",
        "print(rmse)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "56560.31252503457\nCPU times: user 38.3 s, sys: 3.62 s, total: 42 s\nWall time: 13.2 s\n"
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = xgb.XGBRegressor(n_estimators = 197, max_depth=4, learning_rate=0.1818695751227044, subsample= 0.39774994666482544)\n",
        "xgb_model = xgb_model.fit(X_train, y_train)\n",
        "\n",
        "xgb_preds = tensor(xgb_model.predict(test_dl.xs))\n",
        "\n",
        "xgb_preds_x = tensor(xgb_model.predict(X_test))\n",
        "\n",
        "mse = mean_squared_error(y_test, xgb_preds_x)\n",
        "rmse = np.sqrt(mse)\n",
        "print(rmse)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "58988.18613881335\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719387970508
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_model = lgb.LGBMRegressor(num_leaves=251, learning_rate=0.02956613668999794, n_estimators=483, max_depth=82, boosting_type='gbdt',min_child_samples=90, random_state=27)\n",
        "lgb_model = lgb_model.fit(X_train, y_train)\n",
        "\n",
        "#test set preds\n",
        "lgb_preds = tensor(lgb_model.predict(test_dl.xs))\n",
        "\n",
        "#validation set preds\n",
        "lgb_preds_x = tensor(lgb_model.predict(X_test))\n",
        "\n",
        "mse = mean_squared_error(y_test, lgb_preds_x)\n",
        "rmse = np.sqrt(mse)\n",
        "print(rmse)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "57481.14285691434\n"
        }
      ],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719387977194
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#lgb_preds_x.shape,rf_preds_x.shape ,cat_preds_x.shape ,xgb_preds_x.shape,general_preds.shape"
      ],
      "outputs": [],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": true
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719388077090
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "general_preds = (lgb_preds_x + rf_preds_x + cat_preds_x + xgb_preds_x)/4\n",
        "general_preds"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719156570586
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "general_preds_sub = (lgb_preds + rf_preds + cat_preds + xgb_preds)/4\n",
        "general_preds_sub"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719156570704
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "general_preds_sub.shape,cat_preds.shape,lgb_preds.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717671296554
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_absolute_error(y_test, general_preds)\n",
        "rmse = np.sqrt(mse)\n",
        "print(rmse)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717670964526
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv(path/'sample_submission.csv')\n",
        "submit.shape,cat_preds.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 33,
          "data": {
            "text/plain": "((36183, 2), torch.Size([36183]))"
          },
          "metadata": {}
        }
      ],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719157924586
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv(path/'sample_submission.csv')\n",
        "submit['price'] = rf_preds\n",
        "submit.to_csv('submission.csv', index=False)\n",
        "sub = pd.read_csv('submission.csv')\n",
        "sub"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 33,
          "data": {
            "text/plain": "          id      price\n0      54273  21217.232\n1      54274  18184.297\n2      54275  28220.502\n3      54276  74072.016\n4      54277  40165.652\n...      ...        ...\n36178  90451  93780.664\n36179  90452   9515.303\n36180  90453  10171.375\n36181  90454  58793.305\n36182  90455  11464.810\n\n[36183 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>54273</td>\n      <td>21217.232</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>54274</td>\n      <td>18184.297</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>54275</td>\n      <td>28220.502</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>54276</td>\n      <td>74072.016</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54277</td>\n      <td>40165.652</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>36178</th>\n      <td>90451</td>\n      <td>93780.664</td>\n    </tr>\n    <tr>\n      <th>36179</th>\n      <td>90452</td>\n      <td>9515.303</td>\n    </tr>\n    <tr>\n      <th>36180</th>\n      <td>90453</td>\n      <td>10171.375</td>\n    </tr>\n    <tr>\n      <th>36181</th>\n      <td>90454</td>\n      <td>58793.305</td>\n    </tr>\n    <tr>\n      <th>36182</th>\n      <td>90455</td>\n      <td>11464.810</td>\n    </tr>\n  </tbody>\n</table>\n<p>36183 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719388131193
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c kagglex-cohort4 -f submission.csv -m \"rf_preds baseline\""
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/azureuser/.kaggle/kaggle.json'\n100%|████████████████████████████████████████| 552k/552k [00:00<00:00, 1.65MB/s]\n400 - Bad Request - Submission not allowed:  Submissions have been disabled for this competition.\n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This initial submission gave me a score of 76404.555"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dls = to.dataloaders(bs=64)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717671857238
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = tabular_learner(dls, metrics=accuracy)\n",
        "#learn.lr_find(suggest_funcs=(slide,valley))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717673456273
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717673465731
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "learn.fit_one_cycle(10,0.012)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "dl = learn.dls.test_dl(test_df)\n",
        "nn_preds = learn.get_preds(dl=dl)\n",
        "nn_preds_x = learn.get_preds()[0]\n",
        "a_preds, _ = learn.get_preds(dl=dl)\n",
        "nn_preds_y = a_preds.squeeze(1)\n",
        "nn_preds_m = nn_preds_x.squeeze(1)\n",
        "nn_preds_z = nn_preds[0]\n",
        "\n",
        "#target_preds = nn_preds[0]\n",
        "\n",
        "#test_df['Rings'] = target_preds\n",
        "#test_df.to_csv('submission.csv', columns=['Rings'], index=True)\n",
        "\n",
        "#submission = pd.read_csv('submission.csv')\n",
        "#submission.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn_preds_x.shape,nn_preds_y.shape,nn_preds_m.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717673616056
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_absolute_error(y_test, nn_preds_x)\n",
        "rmse_nn = np.sqrt(mse)\n",
        "print(rmse_nn)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717673623170
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_absolute_error(y_test, nn_preds_m)\n",
        "rmse_nn = np.sqrt(mse)\n",
        "print(rmse_nn)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717673634325
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding Original Dataset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_final = pd.concat([train_df,original_df], axis=0)\n",
        "train_final.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "(58282, 12)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717731705114
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cont_names,cat_names = cont_cat_split(train_final, dep_var='price')\n",
        "splits = RandomSplitter(valid_pct=0.2)(range_of(train_final))\n",
        "to = TabularPandas(train_final, procs=[Categorify, FillMissing,Normalize],\n",
        "                   cat_names = cat_names,\n",
        "                   cont_names = cont_names,\n",
        "                   y_names='price',\n",
        "                   splits=splits)\n",
        "\n",
        "X_train, y_train = to.train.xs, to.train.ys.values.ravel()\n",
        "X_test, y_test = to.valid.xs, to.valid.ys.values.ravel()\n",
        "\n",
        "dls = to.dataloaders(bs=64)\n",
        "test_dl = dls.test_dl(test_df)"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717731778840
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "rf = RandomForestRegressor(100, min_samples_leaf=3)\n",
        "rf_model = rf.fit(X_train, y_train);\n",
        "\n",
        "rf_preds = tensor(rf_model.predict(test_dl.xs))\n",
        "\n",
        "rf_preds_x = tensor(rf_model.predict(X_test))\n",
        "\n",
        "mse = mean_absolute_error(y_test, rf_preds_x)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "mse = mean_absolute_error(y_test, rf_preds_x)\n",
        "rmse = np.sqrt(mse)\n",
        "print(rmse)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 18.7 s, sys: 43.5 ms, total: 18.7 s\nWall time: 18.7 s\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_absolute_error(y_test, rf_preds_x)\n",
        "rmse = np.sqrt(mse)\n",
        "print(rmse)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "12.786885\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717731814217
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "cat_model = CatBoostRegressor(iterations=2000, depth=8, learning_rate=  0.08, random_strength=10)\n",
        "cat_model = cat_model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)\n",
        "\n",
        "#test set preds\n",
        "cat_preds = tensor(cat_model.predict(test_dl.xs))\n",
        "\n",
        "#validation set preds\n",
        "cat_preds_x = tensor(cat_model.predict(X_test))\n",
        "\n",
        "cat_mse = mean_absolute_error(y_test, cat_preds_x)\n",
        "cat_rmse = np.sqrt(cat_mse)\n",
        "print(cat_rmse)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "12.714128\nCPU times: user 42.3 s, sys: 2.76 s, total: 45.1 s\nWall time: 13.4 s\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = xgb.XGBRegressor(n_estimators = 197, max_depth=4, learning_rate=0.1818695751227044, subsample= 0.39774994666482544)\n",
        "xgb_model = xgb_model.fit(X_train, y_train)\n",
        "\n",
        "xgb_preds = tensor(xgb_model.predict(test_dl.xs))\n",
        "\n",
        "xgb_preds_x = tensor(xgb_model.predict(X_test))\n",
        "\n",
        "xgb_mse = mean_absolute_error(y_test, xgb_preds_x)\n",
        "xgb_rmse = np.sqrt(xgb_mse)\n",
        "print(xgb_rmse)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "12.814821\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717732003091
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_model = lgb.LGBMRegressor(num_leaves=251, learning_rate=0.02956613668999794, n_estimators=483, max_depth=82, boosting_type='gbdt',min_child_samples=90, random_state=27)\n",
        "lgb_model = lgb_model.fit(X_train, y_train)\n",
        "\n",
        "#test set preds\n",
        "lgb_preds = tensor(lgb_model.predict(test_dl.xs))\n",
        "\n",
        "#validation set preds\n",
        "lgb_preds_x = tensor(lgb_model.predict(X_test))\n",
        "\n",
        "lgb_mse = mean_absolute_error(y_test, lgb_preds_x)\n",
        "lgb_rmse = np.sqrt(lgb_mse)\n",
        "print(lgb_rmse)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "12.719144\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717731949943
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "general_preds = (lgb_preds_x + rf_preds_x + cat_preds_x + xgb_preds_x)/4\n",
        "general_preds"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "tensor([ 730.1823,  609.2162,  215.0769,  ...,  568.4324, 1035.6805,\n         551.1803])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717732008060
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_absolute_error(y_test, general_preds)\n",
        "rmse = np.sqrt(mse)\n",
        "print(rmse)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "12.638833\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717732011678
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "general_preds_sub = (lgb_preds + rf_preds + cat_preds + xgb_preds)/4\n",
        "general_preds_sub"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "tensor([381.6687, 367.4169, 516.5643,  ..., 141.9362, 956.5161, 195.2933])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717732078837
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm submission.csv"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "AutogluonModels  kaggle.json\t\tkagglex-cohort4.zip\r\ncatboost_info\t kaggle_x.ipynb\t\tsubmission.csv\r\ndataset\t\t kaggle_x.ipynb.amltmp\tused-car-price-prediction-dataset.zip\r\n"
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv(path/'sample_submission.csv')\n",
        "submit['price'] = general_preds_sub\n",
        "submit.to_csv('submission.csv', index=False)\n",
        "sub = pd.read_csv('submission.csv')\n",
        "sub"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "          id       price\n0      54273   381.66870\n1      54274   367.41690\n2      54275   516.56430\n3      54276   944.34140\n4      54277   624.46875\n...      ...         ...\n36178  90451  1008.12840\n36179  90452   155.77377\n36180  90453   141.93616\n36181  90454   956.51605\n36182  90455   195.29327\n\n[36183 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>54273</td>\n      <td>381.66870</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>54274</td>\n      <td>367.41690</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>54275</td>\n      <td>516.56430</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>54276</td>\n      <td>944.34140</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54277</td>\n      <td>624.46875</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>36178</th>\n      <td>90451</td>\n      <td>1008.12840</td>\n    </tr>\n    <tr>\n      <th>36179</th>\n      <td>90452</td>\n      <td>155.77377</td>\n    </tr>\n    <tr>\n      <th>36180</th>\n      <td>90453</td>\n      <td>141.93616</td>\n    </tr>\n    <tr>\n      <th>36181</th>\n      <td>90454</td>\n      <td>956.51605</td>\n    </tr>\n    <tr>\n      <th>36182</th>\n      <td>90455</td>\n      <td>195.29327</td>\n    </tr>\n  </tbody>\n</table>\n<p>36183 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717732102867
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c kagglex-cohort4 -f submission.csv -m \"general_preds baseline + original dataset\""
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/azureuser/.kaggle/kaggle.json'\n100%|████████████████████████████████████████| 551k/551k [00:00<00:00, 1.72MB/s]\nSuccessfully submitted to KaggleX Skill Assessment Challenge"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML - AutoGluon"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install AutoGluon"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "predictor = TabularPredictor(label='price').fit(train_data=train_df)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "No path specified. Models will be saved in: \"AutogluonModels/ag-20240607_035321\"\nNo presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\nBeginning AutoGluon training ...\nAutoGluon will save models to \"AutogluonModels/ag-20240607_035321\"\n=================== System Info ===================\nAutoGluon Version:  1.1.0\nPython Version:     3.8.5\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #47~20.04.1-Ubuntu SMP Fri Jun 2 21:38:08 UTC 2023\nCPU Count:          4\nMemory Avail:       29.23 GB / 31.34 GB (93.3%)\nDisk Space Avail:   102398.67 GB / 102400.00 GB (100.0%)\n===================================================\nTrain Data Rows:    54273\nTrain Data Columns: 11\nLabel Column:       price\nAutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n\tLabel info (max, min, mean, stddev): (2954083, 2000, 39218.44333, 72826.33554)\n\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\nProblem Type:       regression\nPreprocessing data ...\nUsing Feature Generators to preprocess the data ...\nFitting AutoMLPipelineFeatureGenerator...\n\tAvailable Memory:                    29966.27 MB\n\tTrain Data (Original)  Memory Usage: 33.50 MB (0.1% of available memory)\n\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n\tStage 1 Generators:\n\t\tFitting AsTypeFeatureGenerator...\n\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n\tStage 2 Generators:\n\t\tFitting FillNaFeatureGenerator...\n\tStage 3 Generators:\n\t\tFitting IdentityFeatureGenerator...\n\t\tFitting CategoryFeatureGenerator...\n\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n\t\tFitting TextSpecialFeatureGenerator...\n\t\t\tFitting BinnedFeatureGenerator...\n\t\t\tFitting DropDuplicatesFeatureGenerator...\n\t\tFitting TextNgramFeatureGenerator...\n\t\t\tFitting CountVectorizer for text features: ['engine']\n\t\t\tCountVectorizer fit with vocabulary size = 113\n\tStage 4 Generators:\n\t\tFitting DropUniqueFeatureGenerator...\n\tStage 5 Generators:\n\t\tFitting DropDuplicatesFeatureGenerator...\n\tUseless Original Features (Count: 1): ['clean_title']\n\t\tThese features carry no predictive signal and should be manually investigated.\n\t\tThis is typically a feature which has the same value for all rows.\n\t\tThese features do not need to be present at inference time.\n\tTypes of features in original data (raw dtype, special dtypes):\n\t\t('int', [])          : 2 | ['model_year', 'milage']\n\t\t('object', [])       : 7 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n\t\t('object', ['text']) : 1 | ['engine']\n\tTypes of features in processed data (raw dtype, special dtypes):\n\t\t('category', [])                    :  6 | ['brand', 'model', 'fuel_type', 'transmission', 'ext_col', ...]\n\t\t('category', ['text_as_category'])  :  1 | ['engine']\n\t\t('int', [])                         :  2 | ['model_year', 'milage']\n\t\t('int', ['binned', 'text_special']) : 11 | ['engine.char_count', 'engine.word_count', 'engine.capital_ratio', 'engine.lower_ratio', 'engine.digit_ratio', ...]\n\t\t('int', ['bool'])                   :  1 | ['accident']\n\t\t('int', ['text_ngram'])             : 59 | ['__nlp__.0hp', '__nlp__.0hp 0l', '__nlp__.0hp 0l cylinder', '__nlp__.0hp 0l straight', '__nlp__.0hp 0l v6', ...]\n\t7.3s = Fit runtime\n\t10 features in original data used to generate 80 features in processed data.\n\tTrain Data (Processed) Memory Usage: 8.08 MB (0.0% of available memory)\nData preprocessing and feature engineering runtime = 7.38s ...\nAutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n\tTo change this, specify the eval_metric parameter of Predictor()\nAutomatically generating train/validation split with holdout_frac=0.046063420116816835, Train Rows: 51773, Val Rows: 2500\nUser-specified model hyperparameters to be fit:\n{\n\t'NN_TORCH': {},\n\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n\t'CAT': {},\n\t'XGB': {},\n\t'FASTAI': {},\n\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n}\nFitting 11 L1 models ...\nFitting model: KNeighborsUnif ...\n\t-41763.7305\t = Validation score   (-root_mean_squared_error)\n\t2.46s\t = Training   runtime\n\t0.54s\t = Validation runtime\nFitting model: KNeighborsDist ...\n\t-59487.184\t = Validation score   (-root_mean_squared_error)\n\t1.25s\t = Training   runtime\n\t0.39s\t = Validation runtime\nFitting model: LightGBMXT ...\n\t-32736.1495\t = Validation score   (-root_mean_squared_error)\n\t2.17s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: LightGBM ...\n\t-34822.0745\t = Validation score   (-root_mean_squared_error)\n\t2.17s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: RandomForestMSE ...\n\t-52640.2324\t = Validation score   (-root_mean_squared_error)\n\t74.33s\t = Training   runtime\n\t0.16s\t = Validation runtime\nFitting model: CatBoost ...\n\t-32778.797\t = Validation score   (-root_mean_squared_error)\n\t11.53s\t = Training   runtime\n\t0.02s\t = Validation runtime\nFitting model: ExtraTreesMSE ...\n\t-48297.2169\t = Validation score   (-root_mean_squared_error)\n\t40.72s\t = Training   runtime\n\t0.16s\t = Validation runtime\nFitting model: NeuralNetFastAI ...\nNo improvement since epoch 1: early stopping\n\t-33837.392\t = Validation score   (-root_mean_squared_error)\n\t39.31s\t = Training   runtime\n\t0.05s\t = Validation runtime\nFitting model: XGBoost ...\n\t-37017.7533\t = Validation score   (-root_mean_squared_error)\n\t2.97s\t = Training   runtime\n\t0.02s\t = Validation runtime\nFitting model: NeuralNetTorch ...\n\t-33668.1529\t = Validation score   (-root_mean_squared_error)\n\t34.82s\t = Training   runtime\n\t0.02s\t = Validation runtime\nFitting model: LightGBMLarge ...\n\t-36188.3865\t = Validation score   (-root_mean_squared_error)\n\t2.67s\t = Training   runtime\n\t0.01s\t = Validation runtime\nFitting model: WeightedEnsemble_L2 ...\n\tEnsemble Weights: {'LightGBMXT': 0.429, 'CatBoost': 0.357, 'NeuralNetTorch': 0.143, 'NeuralNetFastAI': 0.071}\n\t-32260.5732\t = Validation score   (-root_mean_squared_error)\n\t0.02s\t = Training   runtime\n\t0.0s\t = Validation runtime\nAutoGluon training complete, total runtime = 237.14s ... Best model: \"WeightedEnsemble_L2\"\nTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240607_035321\")\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 10min 5s, sys: 4.38 s, total: 10min 10s\nWall time: 3min 57s\n"
        }
      ],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "predictions = predictor.predict(test_df)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 2.52 s, sys: 39.9 ms, total: 2.56 s\nWall time: 2.14 s\n"
        }
      ],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 32,
          "data": {
            "text/plain": "id\n54273    23219.078125\n54274    23511.646484\n54275    40694.859375\n54276    56333.109375\n54277    36551.843750\n             ...     \n90451    70927.515625\n90452    52173.867188\n90453    13193.083984\n90454    55341.703125\n90455    24132.984375\nName: price, Length: 36183, dtype: float32"
          },
          "metadata": {}
        }
      ],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717732440430
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "predictor.evaluate(train_df)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 3.93 s, sys: 52.2 ms, total: 3.98 s\nWall time: 2.95 s\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 33,
          "data": {
            "text/plain": "{'root_mean_squared_error': -65665.22506090587,\n 'mean_squared_error': -4311921782.299419,\n 'mean_absolute_error': -16564.72589797219,\n 'r2': 0.18697863036499762,\n 'pearsonr': 0.449699835387118,\n 'median_absolute_error': -8163.80859375}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm submission.csv"
      ],
      "outputs": [],
      "execution_count": 42,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "AutogluonModels  kaggle.json\t\tkagglex-cohort4.zip\r\ncatboost_info\t kaggle_x.ipynb\t\tused-car-price-prediction-dataset.zip\r\ndataset\t\t kaggle_x.ipynb.amltmp\r\n"
        }
      ],
      "execution_count": 43,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717681460328
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Investigate if there is a difference in score based on the submission steps used."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#currently preffered submission style\n",
        "submit = pd.read_csv(path/'sample_submission.csv')\n",
        "submit['price'] = predictions\n",
        "submit.to_csv('submission.csv', index=False)\n",
        "sub = pd.read_csv('submission.csv')\n",
        "sub"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 37,
          "data": {
            "text/plain": "          id  price\n0      54273    NaN\n1      54274    NaN\n2      54275    NaN\n3      54276    NaN\n4      54277    NaN\n...      ...    ...\n36178  90451    NaN\n36179  90452    NaN\n36180  90453    NaN\n36181  90454    NaN\n36182  90455    NaN\n\n[36183 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>54273</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>54274</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>54275</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>54276</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54277</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>36178</th>\n      <td>90451</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>36179</th>\n      <td>90452</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>36180</th>\n      <td>90453</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>36181</th>\n      <td>90454</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>36182</th>\n      <td>90455</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>36183 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717732636866
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#seems to work better for submissions\n",
        "test_df['price'] = predictions\n",
        "test_df.to_csv('submission.csv', columns=['price'], index=True)\n",
        "\n",
        "submission = pd.read_csv('submission.csv')\n",
        "submission.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 44,
          "data": {
            "text/plain": "      id      price\n0  54273  23219.078\n1  54274  23511.646\n2  54275  40694.860\n3  54276  56333.110\n4  54277  36551.844",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>54273</td>\n      <td>23219.078</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>54274</td>\n      <td>23511.646</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>54275</td>\n      <td>40694.860</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>54276</td>\n      <td>56333.110</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54277</td>\n      <td>36551.844</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 44,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1717732759903
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c kagglex-cohort4 -f submission.csv -m \"AutoGluon Baseline\""
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/azureuser/.kaggle/kaggle.json'\n100%|████████████████████████████████████████| 553k/553k [00:00<00:00, 1.94MB/s]\nSuccessfully submitted to KaggleX Skill Assessment Challenge"
        }
      ],
      "execution_count": 46,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "AutogluonModels  kaggle.json\t\tkagglex-cohort4.zip\r\ncatboost_info\t kaggle_x.ipynb\t\tsubmission.csv\r\ndataset\t\t kaggle_x.ipynb.amltmp\tused-car-price-prediction-dataset.zip\r\n"
        }
      ],
      "execution_count": 45,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openfe import OpenFE, transform\n",
        "\n",
        "ofe = OpenFE()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_names='Target'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.8 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}